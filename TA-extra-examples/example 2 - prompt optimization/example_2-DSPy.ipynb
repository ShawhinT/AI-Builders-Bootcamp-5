{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12851a3e",
   "metadata": {},
   "source": [
    "# DSPy Overview\n",
    "\n",
    "First and foremost, DSPy is a Python library for programatically optimizing LLM prompting. The fundamental insight is that standard prompts conflate interface (\"what should the LM do?\") with implementation (\"how do we tell it to do that?\").\n",
    "\n",
    "Over time our LLM systems generate a wealth of question-answer pairs from users that we can use with DSPy to optimize our prompts with little to no effort on our part. All we need is a metric to evaluate the quality of the answers.\n",
    "\n",
    "## How DSPy Works\n",
    "\n",
    "We could think of each interaction with an LLM in terms of simple algebra: \n",
    "$$LLM(Q)  = \\text{Response}$$\n",
    "\n",
    "Where $Q = \\text{User Prompt} + \\text{System Prompt} + \\text{Context}$\n",
    "\n",
    "DSPy essentially optimizes the LLM responses by tuning the Q function. This is distinct from fine-tuning, which in our algebra example would adjust the function $LLM(Q)$, as well as from RAG which adjusts the $\\text{Context}$.\n",
    "\n",
    "To do this, we create:\n",
    "1. **Inputs** that are specific to the LLM's task - basically, what things the LLM should look for in the input $Q$ to determine it's response. These are semantic data fields.\n",
    "2. **Outputs** that are the LLM's responses given our inputs.\n",
    "3. **Metrics** that return a score quantifying how good the output is.\n",
    "\n",
    "All of these together are called a **signature**. DSPy uses these signatures to determine the the value of $Q$ that maximizes the metric. Here's an example of what that might look like:\n",
    "\n",
    "```python\n",
    "class QASignature(dspy.Signature):\n",
    "    \"\"\"Answer questions clearly.\"\"\"  # ← This becomes system context\n",
    "    question: str = dspy.InputField()   # Input schema\n",
    "    context: str = dspy.InputField()    # Input schema  \n",
    "    answer: str = dspy.OutputField()    # Output schema\n",
    "```\n",
    "\n",
    "This way, we don't have to worry about how the LLM implements the task - we just need to tell it what the task is.\n",
    "\n",
    "## Example\n",
    "\n",
    "This notebook will go through a simple example for how how DSPy can solve the LinkedIn ghostwriter problem discussed in [Shaw's Medium post](https://medium.com/@shawhin/how-to-improve-ai-apps-with-error-analysis-4af5f163a1d1), but using systematic optimization instead of manual error analysis and prompt engineering. \n",
    "\n",
    "For a more in-depth walkthrough, check out Adam Lucek's walkthrough: https://github.com/ALucek/dspy-breakdown/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bdd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5425427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test! How can I assist you further?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = dspy.LM('openai/gpt-4o-mini')\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "lm(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9962c",
   "metadata": {},
   "source": [
    "## Step 1: Define the Problem with DSPy Signatures\n",
    "\n",
    "Instead of crafting complex prompts, we define what we want using DSPy signatures. This separates the \"what\" (interface) from the \"how\" (implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dbacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInPostSignature(dspy.Signature):\n",
    "    \"\"\"Generate engaging LinkedIn posts in Shaw Talebi's style from post ideas.\"\"\"\n",
    "    \n",
    "    post_idea: str = dspy.InputField(desc=\"Raw post idea or notes\")\n",
    "    author_context: str = dspy.InputField(desc=\"Context about the author's style and expertise\")\n",
    "    \n",
    "    hook: str = dspy.OutputField(desc=\"Engaging opening line that grabs attention\")\n",
    "    post_content: str = dspy.OutputField(desc=\"Full LinkedIn post content\")\n",
    "    call_to_action: str = dspy.OutputField(desc=\"Single, clear call-to-action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05519756",
   "metadata": {},
   "source": [
    "## Step 2: Create DSPy Module\n",
    "\n",
    "We'll use ChainOfThought to encourage structured reasoning about post creation. The key insight is that this encapsulates LinkedIn post generation as an optimizable DSPy module rather than a static prompt, allowing the system to learn better post creation strategies over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f39974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInGhostwriter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use ChainOfThought for better reasoning\n",
    "        self.generate_post = dspy.ChainOfThought(LinkedInPostSignature)\n",
    "    \n",
    "    def forward(self, post_idea: str, author_context: str = None):\n",
    "        if author_context is None:\n",
    "            author_context = \"\"\"Shaw Talebi is a data scientist and AI educator who:\n",
    "            - Writes practical, actionable content about AI/ML\n",
    "            - Uses numbered lists and clear structure\n",
    "            - Focuses on helping people break into AI careers\n",
    "            - Maintains a friendly but professional tone\n",
    "            - Often asks engaging questions to drive interaction\"\"\"\n",
    "        \n",
    "        result = self.generate_post(\n",
    "            post_idea=post_idea,\n",
    "            author_context=author_context\n",
    "        )\n",
    "        \n",
    "        # Combine components into final post\n",
    "        final_post = f\"{result.hook}\\n\\n{result.post_content}\\n\\n{result.call_to_action}\"\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            hook=result.hook,\n",
    "            post_content=result.post_content,\n",
    "            call_to_action=result.call_to_action,\n",
    "            final_post=final_post,\n",
    "            reasoning=result.reasoning if hasattr(result, 'reasoning') else \"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f7d22",
   "metadata": {},
   "source": [
    "## Step 3: Create Training Data\n",
    "\n",
    "Instead of manually analyzing 49 examples, we create Examples with quality indicators that DSPy can learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde24515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 training examples\n"
     ]
    }
   ],
   "source": [
    "# Sample post ideas (similar to the blog post)\n",
    "post_ideas = [\n",
    "    \"Different ways to make money with AI skills beyond getting a traditional job\",\n",
    "    \"Common mistakes people make when starting their AI journey\",\n",
    "    \"Why networking is crucial for breaking into AI careers\",\n",
    "    \"How to build an AI portfolio that actually gets you hired\",\n",
    "    \"The truth about AI certifications - do they really matter?\",\n",
    "    \"5 Python libraries every data scientist should know\",\n",
    "    \"How to transition from another field into AI/ML\",\n",
    "    \"Why you should start with small AI projects, not big ones\",\n",
    "    \"The most important skills for AI jobs in 2025\",\n",
    "    \"How to stay updated with rapidly changing AI landscape\"\n",
    "]\n",
    "\n",
    "# Sample high-quality posts (what good outputs should look like)\n",
    "good_examples = [\n",
    "    dspy.Example(\n",
    "        post_idea=\"Different ways to make money with AI skills beyond getting a traditional job\",\n",
    "        final_post=\"\"\"\n",
    "        Landing a job isn't the only way to make money with AI. Here's how you can turn your AI skills into income—no matter your background:\n",
    "        1. **Get a job:** Land a full-time role as a machine learning engineer, data scientist, or prompt engineer. The fastest way to steady income and learning.\n",
    "        2. **Implementation:** Help teams build and deploy real AI solutions as a freelancer or contractor. Solve specific technical problems for businesses.\n",
    "        3. **Strategy & Consulting:** Guide founders, managers, or non-technical teams on what's possible (and what's hype), helping them make smarter decisions.\n",
    "        4. **Education:** Teach others—run workshops, create courses, write tutorials, or build a YouTube channel. There's a hungry audience eager to learn.\n",
    "        5. **Products:** Build your own SaaS, tools, or micro products powered by AI. Riskier, but the most scalable path if you can nail a real pain point.\n",
    "\n",
    "        Which path are you focused on right now?\"\"\",\n",
    "        quality_score=9\n",
    "    ),\n",
    "    dspy.Example(\n",
    "        post_idea=\"Common mistakes people make when starting their AI journey\",\n",
    "        final_post=\"\"\"\n",
    "            Starting in AI? Avoid these 5 costly mistakes I see everywhere:\n",
    "            1. **Tutorial Hell:** Watching endless courses without building anything. Theory is important, but projects teach you what really matters.\n",
    "            2. **Perfect Project Syndrome:** Waiting for the \"perfect\" dataset or idea. Start messy, iterate fast, and learn from real problems.\n",
    "            3. **Ignoring the Business Side:** Building cool tech that solves no real problem. Always ask: \"Who would pay for this and why?\"\n",
    "            4. **Going Solo Too Long:** AI is collaborative. Join communities, find mentors, and work on teams. Your network is your net worth.\n",
    "            5. **Chasing Shiny Objects:** Jumping from deep learning to MLOps to LLMs without depth. Pick one area and go deep first.\n",
    "\n",
    "            Your first project won't be perfect—and that's exactly the point.\n",
    "\n",
    "            What mistake would you add to this list?\"\"\",\n",
    "        quality_score=8\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create training set by mixing good examples with generated ones\n",
    "def create_training_data():\n",
    "    \"\"\"Create training examples with quality scores.\"\"\"\n",
    "    training_examples = []\n",
    "    \n",
    "    # Add our curated good examples\n",
    "    training_examples.extend(good_examples)\n",
    "    \n",
    "    # For remaining post ideas, we'll generate examples and assign quality scores\n",
    "    # In practice, you'd have human evaluators or automated metrics\n",
    "    remaining_ideas = [idea for idea in post_ideas if not any(idea in ex.post_idea for ex in good_examples)]\n",
    "    \n",
    "    for idea in remaining_ideas:\n",
    "        training_examples.append(\n",
    "            dspy.Example(\n",
    "                post_idea=idea,\n",
    "                quality_score=random.randint(5, 8)  # Simulated quality scores\n",
    "            ).with_inputs(\"post_idea\")\n",
    "        )\n",
    "    \n",
    "    return training_examples\n",
    "\n",
    "trainset = create_training_data()\n",
    "print(f\"Created {len(trainset)} training examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc8355",
   "metadata": {},
   "source": [
    "## Step 4: Define Evaluation Metrics\n",
    " \n",
    "Instead of manually categorizing errors, we define metrics that capture what makes a good LinkedIn post. These can be anything you want.\n",
    "\n",
    "An important note to make is that for DSPy, leading metrics are usually better than lagging metrics for optimization. For isntance if optimizing a social media agent, *post length* would likely be better than *likes* or *number of comments*. This is because external factors can influence the lagging metrics, such as the time of day or the current trending topics. Sometimes though it is best to try a combination of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72424893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_post_metric(example, prediction, trace=None) -> float:\n",
    "    \"\"\"\n",
    "    Comprehensive metric for LinkedIn post quality.\n",
    "    Returns a score from 0 to 1.\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # Check if we have a quality score in the example\n",
    "    if hasattr(example, 'quality_score'):\n",
    "        # Normalize quality score to 0-1 range\n",
    "        target_score = example.quality_score / 10.0\n",
    "    else:\n",
    "        target_score = 0.7  # Default expectation\n",
    "    \n",
    "    # Basic checks that can be automated\n",
    "    post = prediction.final_post if hasattr(prediction, 'final_post') else str(prediction)\n",
    "    \n",
    "    # 1. Length check (LinkedIn posts should be substantial but not too long)\n",
    "    if 200 <= len(post) <= 1500:\n",
    "        score += 0.2\n",
    "    \n",
    "    # 2. Structure check (should have clear formatting)\n",
    "    if any(marker in post for marker in ['1.', '2.', '3.', '•', '-', '**']):\n",
    "        score += 0.2\n",
    "    \n",
    "    # 3. Engagement check (should end with a question or CTA)\n",
    "    if post.strip().endswith('?') or any(cta in post.lower() for cta in ['what do you think', 'which', 'how', 'share your']):\n",
    "        score += 0.2\n",
    "    \n",
    "    # 4. Professional tone check (avoid certain words/phrases)\n",
    "    if not any(word in post.lower() for word in ['amazing', 'incredible', 'mind-blowing', 'game-changer']):\n",
    "        score += 0.2\n",
    "    \n",
    "    # 5. Content structure (should have hook + body + CTA)\n",
    "    lines = post.strip().split('\\n')\n",
    "    if len(lines) >= 3:  # At least hook, body, CTA\n",
    "        score += 0.2\n",
    "    \n",
    "    # Weight the score by target quality if available\n",
    "    if hasattr(example, 'quality_score'):\n",
    "        score = score * target_score + (1 - target_score) * 0.5\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "# Advanced metric using LLM-as-a-judge for nuanced evaluation\n",
    "class LLMJudgeMetric(dspy.Module):\n",
    "    \"\"\"Use an LLM to evaluate post quality on multiple dimensions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.judge = dspy.ChainOfThought(\"post, criteria -> score: float, reasoning: str\")\n",
    "    \n",
    "    def forward(self, example, prediction):\n",
    "        post = prediction.final_post if hasattr(prediction, 'final_post') else str(prediction)\n",
    "        \n",
    "        criteria = \"\"\"Evaluate this LinkedIn post on:\n",
    "        1. Engagement (hook, question, relatability) - 25%\n",
    "        2. Value (actionable insights, practical advice) - 25% \n",
    "        3. Structure (clear formatting, easy to read) - 25%\n",
    "        4. Professional tone (authoritative but approachable) - 25%\n",
    "        \n",
    "        Return a score from 0.0 to 1.0.\"\"\"\n",
    "        \n",
    "        result = self.judge(post=post, criteria=criteria)\n",
    "        return float(result.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da15634",
   "metadata": {},
   "source": [
    "## Step 5: DSPy Optimization\n",
    "\n",
    "Now we let DSPy automatically optimize our module instead of manual error analysis. The key insight is that this establishes measurable baseline performance so you can quantify the actual improvement that DSPy's automatic optimization delivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944c01d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNOPTIMIZED VERSION ===\n",
      "Post: Are you struggling to break into the AI industry? The secret might just lie in your network!\n",
      "\n",
      "Breaking into an AI career can feel daunting, but one of the most powerful tools at your disposal is your network. Here’s why networking is crucial for your success in the AI field:\n",
      "\n",
      "1. **Access to Opportunities**: Many job openings are never advertised. Networking can help you tap into the hidden job market and discover roles that align with your skills.\n",
      "\n",
      "2. **Industry Insights**: Engaging with professionals in the field allows you to gain valuable insights into the latest trends, tools, and technologies in AI.\n",
      "\n",
      "3. **Mentorship**: Building relationships with experienced professionals can provide you with guidance, support, and advice as you navigate your career path.\n",
      "\n",
      "4. **Collaboration**: Networking can lead to collaborative projects that enhance your portfolio and showcase your skills to potential employers.\n",
      "\n",
      "5. **Confidence Boost**: Connecting with others who share your interests can motivate you and boost your confidence as you pursue your career goals.\n",
      "\n",
      "Remember, networking isn’t just about what you can gain; it’s also about what you can offer. Be genuine, share your knowledge, and build meaningful relationships.\n",
      "\n",
      "What strategies have you found effective for networking in the AI space? Let’s discuss!\n",
      "\n",
      "Share your networking tips in the comments below!\n",
      "\n",
      "Baseline average score: 0.814\n"
     ]
    }
   ],
   "source": [
    "# Initialize our ghostwriter\n",
    "ghostwriter = LinkedInGhostwriter()\n",
    "\n",
    "# Test unoptimized version\n",
    "print(\"=== UNOPTIMIZED VERSION ===\")\n",
    "test_idea = \"Why networking is crucial for breaking into AI careers\"\n",
    "unoptimized_result = ghostwriter(test_idea)\n",
    "print(f\"Post: {unoptimized_result.final_post}\\n\")\n",
    "\n",
    "# Evaluate baseline performance\n",
    "baseline_scores = []\n",
    "for example in trainset[:5]:  # Test on subset\n",
    "    pred = ghostwriter(example.post_idea)\n",
    "    score = linkedin_post_metric(example, pred)\n",
    "    baseline_scores.append(score)\n",
    "\n",
    "baseline_avg = sum(baseline_scores) / len(baseline_scores)\n",
    "print(f\"Baseline average score: {baseline_avg:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9b708",
   "metadata": {},
   "source": [
    "## Step 6: Compile with DSPy Optimizer\n",
    "\n",
    "Use MIPRO optimizer to automatically improve prompts and examples.\n",
    "\n",
    "The most important part is the ```compile()``` method - DSPy automatically experiments with different prompt constructions, instruction phrasings, and example selections to find the optimal configuration that maximizes the metric on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac89a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 10\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 2\n",
      "\n",
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 8 examples\n",
      "Validating on 2 examples\n",
      "Optimizing... This may take a few minutes.\n",
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:41 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'post_idea': 'Common mistakes people make when starting their AI journey', 'final_post': '\\n            Starting in AI? Avoid these 5 costly mistakes I see everywhere:\\n            1. **Tutorial Hell:** Watching endless courses without building anything. Theory is important, but projects teach you what really matters.\\n            2. **Perfect Project Syndrome:** Waiting for the \"perfect\" dataset or idea. Start messy, iterate fast, and learn from real problems.\\n            3. **Ignoring the Business Side:** Building cool tech that solves no real problem. Always ask: \"Who would pay for this and why?\"\\n            4. **Going Solo Too Long:** AI is collaborative. Join communities, find mentors, and work on teams. Your network is your net worth.\\n            5. **Chasing Shiny Objects:** Jumping from deep learning to MLOps to LLMs without depth. Pick one area and go deep first.\\n\\n            Your first project won\\'t be perfect—and that\\'s exactly the point.\\n\\n            What mistake would you add to this list?', 'quality_score': 8}) (input_keys=None) with <function linkedin_post_metric at 0x00000245424027A0> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      " 50%|█████     | 4/8 [00:00<00:00, 444.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:41 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'post_idea': 'Different ways to make money with AI skills beyond getting a traditional job', 'final_post': \"\\n        Landing a job isn't the only way to make money with AI. Here's how you can turn your AI skills into income—no matter your background:\\n        1. **Get a job:** Land a full-time role as a machine learning engineer, data scientist, or prompt engineer. The fastest way to steady income and learning.\\n        2. **Implementation:** Help teams build and deploy real AI solutions as a freelancer or contractor. Solve specific technical problems for businesses.\\n        3. **Strategy & Consulting:** Guide founders, managers, or non-technical teams on what's possible (and what's hype), helping them make smarter decisions.\\n        4. **Education:** Teach others—run workshops, create courses, write tutorials, or build a YouTube channel. There's a hungry audience eager to learn.\\n        5. **Products:** Build your own SaaS, tools, or micro products powered by AI. Riskier, but the most scalable path if you can nail a real pain point.\\n\\n        Which path are you focused on right now?\", 'quality_score': 9}) (input_keys=None) with <function linkedin_post_metric at 0x00000245424027A0> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      " 50%|█████     | 4/8 [00:00<00:00, 651.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:00, 499.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:00, 333.17it/s]\n",
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/07/08 15:51:41 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Error getting source code: unhashable type: 'dict'.\n",
      "\n",
      "Running without program aware proposer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:46 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Generate engaging LinkedIn posts in Shaw Talebi's style from post ideas.\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Imagine you are an aspiring data scientist looking to make your mark in the competitive AI job market. You need to create engaging LinkedIn posts that not only showcase your knowledge but also resonate with your audience in the style of Shaw Talebi. Generate a series of actionable and structured posts based on the provided ideas, ensuring to include hooks, clear steps, and engaging questions that encourage interaction. Remember, your posts should guide readers in overcoming common challenges in their AI careers while maintaining a friendly yet professional tone.\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are an AI educator and data scientist, Shaw Talebi. Generate engaging LinkedIn posts based on the provided post ideas, using a friendly yet professional tone. Structure your posts with clear, actionable steps in numbered lists, and include engaging hooks and calls to action that encourage audience interaction.\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 10 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.65 / 2 (82.5%): 100%|██████████| 2/2 [00:00<00:00, 2003.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:51 INFO dspy.evaluate.evaluate: Average Metric: 1.65 / 2 (82.5%)\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 82.5\n",
      "\n",
      "2025/07/08 15:51:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.45 / 2 (72.5%): 100%|██████████| 2/2 [00:06<00:00,  3.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:51:58 INFO dspy.evaluate.evaluate: Average Metric: 1.4500000000000002 / 2 (72.5%)\n",
      "2025/07/08 15:51:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/07/08 15:51:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5]\n",
      "2025/07/08 15:51:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:51:58 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:51:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.39 / 2 (69.5%): 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:06 INFO dspy.evaluate.evaluate: Average Metric: 1.3900000000000001 / 2 (69.5%)\n",
      "2025/07/08 15:52:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/07/08 15:52:06 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5]\n",
      "2025/07/08 15:52:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:06 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:06 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.39 / 2 (69.5%): 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:13 INFO dspy.evaluate.evaluate: Average Metric: 1.3900000000000001 / 2 (69.5%)\n",
      "2025/07/08 15:52:13 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/07/08 15:52:13 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5]\n",
      "2025/07/08 15:52:13 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:13 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:13 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.39 / 2 (69.5%): 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:21 INFO dspy.evaluate.evaluate: Average Metric: 1.3900000000000001 / 2 (69.5%)\n",
      "2025/07/08 15:52:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/07/08 15:52:21 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5]\n",
      "2025/07/08 15:52:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:21 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.55 / 2 (77.5%): 100%|██████████| 2/2 [00:09<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:31 INFO dspy.evaluate.evaluate: Average Metric: 1.55 / 2 (77.5%)\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5]\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.39 / 2 (69.5%): 100%|██████████| 2/2 [00:00<00:00, 981.01it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:31 INFO dspy.evaluate.evaluate: Average Metric: 1.3900000000000001 / 2 (69.5%)\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5, 69.5]\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.55 / 2 (77.5%): 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:38 INFO dspy.evaluate.evaluate: Average Metric: 1.55 / 2 (77.5%)\n",
      "2025/07/08 15:52:38 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/07/08 15:52:38 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5, 69.5, 77.5]\n",
      "2025/07/08 15:52:38 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:38 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:38 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.39 / 2 (69.5%): 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:46 INFO dspy.evaluate.evaluate: Average Metric: 1.3900000000000001 / 2 (69.5%)\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5, 69.5, 77.5, 69.5]\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.55 / 2 (77.5%): 100%|██████████| 2/2 [00:00<00:00, 1003.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:46 INFO dspy.evaluate.evaluate: Average Metric: 1.55 / 2 (77.5%)\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5, 69.5, 77.5, 69.5, 77.5]\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.65 / 2 (82.5%): 100%|██████████| 2/2 [00:00<00:00, 399.80it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 15:52:46 INFO dspy.evaluate.evaluate: Average Metric: 1.65 / 2 (82.5%)\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [82.5, 72.5, 69.5, 69.5, 69.5, 77.5, 69.5, 77.5, 69.5, 77.5, 82.5]\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 82.5\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/07/08 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 82.5!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization complete!\n"
     ]
    }
   ],
   "source": [
    "# Split data for optimization\n",
    "random.shuffle(trainset)\n",
    "train_size = int(0.8 * len(trainset))\n",
    "train_data = trainset[:train_size]\n",
    "val_data = trainset[train_size:]\n",
    "\n",
    "print(f\"Training on {len(train_data)} examples\")\n",
    "print(f\"Validating on {len(val_data)} examples\")\n",
    "\n",
    "# Configure optimizer\n",
    "optimizer = dspy.MIPROv2(\n",
    "    metric=linkedin_post_metric,\n",
    "    auto=\"light\",\n",
    "    max_bootstrapped_demos=3,\n",
    "    max_labeled_demos=2\n",
    ")\n",
    "\n",
    "# Compile the optimized version\n",
    "print(\"Optimizing... This may take a few minutes.\")\n",
    "optimized_ghostwriter = optimizer.compile(\n",
    "    ghostwriter,\n",
    "    trainset=train_data,\n",
    "    valset=val_data,\n",
    "    requires_permission_to_run=False\n",
    ")\n",
    "\n",
    "print(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d173f23",
   "metadata": {},
   "source": [
    "## Step 7: Compare Results\n",
    "\n",
    "Evaluate the optimized version against the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da427ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPTIMIZED VERSION ===\n",
      "Post: Are you struggling to break into the AI industry? The secret might just lie in your network!\n",
      "\n",
      "Breaking into an AI career can feel daunting, but one of the most powerful tools at your disposal is your network. Here’s why networking is crucial for your success in the AI field:\n",
      "\n",
      "1. **Access to Opportunities**: Many job openings are never advertised. Networking can help you tap into the hidden job market and discover roles that align with your skills.\n",
      "\n",
      "2. **Industry Insights**: Engaging with professionals in the field allows you to gain valuable insights into the latest trends, tools, and technologies in AI.\n",
      "\n",
      "3. **Mentorship**: Building relationships with experienced professionals can provide you with guidance, support, and advice as you navigate your career path.\n",
      "\n",
      "4. **Collaboration**: Networking can lead to collaborative projects that enhance your portfolio and showcase your skills to potential employers.\n",
      "\n",
      "5. **Confidence Boost**: Connecting with others who share your interests can motivate you and boost your confidence as you pursue your career goals.\n",
      "\n",
      "Remember, networking isn’t just about what you can gain; it’s also about what you can offer. Be genuine, share your knowledge, and build meaningful relationships.\n",
      "\n",
      "What strategies have you found effective for networking in the AI space? Let’s discuss!\n",
      "\n",
      "Share your networking tips in the comments below!\n",
      "\n",
      "Baseline average score: 0.814\n",
      "Optimized average score: 0.840\n",
      "Improvement: 3.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== OPTIMIZED VERSION ===\")\n",
    "optimized_result = optimized_ghostwriter(test_idea)\n",
    "print(f\"Post: {optimized_result.final_post}\\n\")\n",
    "\n",
    "# Evaluate optimized performance\n",
    "optimized_scores = []\n",
    "for example in trainset[:5]:\n",
    "    pred = optimized_ghostwriter(example.post_idea)\n",
    "    score = linkedin_post_metric(example, pred)\n",
    "    optimized_scores.append(score)\n",
    "\n",
    "optimized_avg = sum(optimized_scores) / len(optimized_scores)\n",
    "improvement = ((optimized_avg - baseline_avg) / baseline_avg) * 100\n",
    "\n",
    "print(f\"Baseline average score: {baseline_avg:.3f}\")\n",
    "print(f\"Optimized average score: {optimized_avg:.3f}\")\n",
    "print(f\"Improvement: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef73757",
   "metadata": {},
   "source": [
    "## Step 8: Analyze What DSPy Learned\n",
    "\n",
    "The code below bridges the gap between DSPy's \"black box\" optimization and human understanding, allowing developers to validate that the optimization worked as intended and gain insights into what makes a good LinkedIn post according to the learned model.\n",
    "\n",
    "The key idea is that this provides both confidence in the optimization results and understanding of what DSPy discovered about effective content creation. This is an alternative to manual error categorization outlined in the Medium article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5765cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DSPy OPTIMIZATION ANALYSIS ===\n",
      "\n",
      "=== CONSISTENCY CHECK ===\n",
      "\n",
      "Test 1: How to build an AI portfolio that actually gets you hired\n",
      "Quality Score: 0.800\n",
      "Hook: Are you ready to land your dream job in AI? Your portfolio could be the key!\n",
      "CTA: Start building your AI portfolio today and share your progress with me!\n",
      "\n",
      "Test 2: The most important skills for AI jobs in 2025\n",
      "Quality Score: 1.000\n",
      "Hook: Are you ready to future-proof your career in AI? Here are the top skills you’ll need by 2025!\n",
      "CTA: Share your thoughts on which skills you believe are essential for AI careers in the comments below!\n",
      "\n",
      "Test 3: Why you should start with small AI projects, not big ones\n",
      "Quality Score: 1.000\n",
      "Hook: Thinking about diving into AI? Start small—here's why!\n",
      "CTA: Share your thoughts or your first small AI project idea in the comments below!\n"
     ]
    }
   ],
   "source": [
    "def analyze_optimizations(optimized_module):\n",
    "    \"\"\"Analyze what DSPy learned during optimization.\"\"\"\n",
    "    \n",
    "    print(\"=== DSPy OPTIMIZATION ANALYSIS ===\")\n",
    "    \n",
    "    # Check if we can access the optimized prompts\n",
    "    if hasattr(optimized_module, 'generate_post'):\n",
    "        module = optimized_module.generate_post\n",
    "        if hasattr(module, 'signature'):\n",
    "            print(\"Optimized Signature:\")\n",
    "            print(f\"Docstring: {module.signature.__doc__}\")\n",
    "    \n",
    "    # Test with multiple examples to see consistency\n",
    "    test_cases = [\n",
    "        \"How to build an AI portfolio that actually gets you hired\",\n",
    "        \"The most important skills for AI jobs in 2025\",\n",
    "        \"Why you should start with small AI projects, not big ones\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n=== CONSISTENCY CHECK ===\")\n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        result = optimized_module(test_case)\n",
    "        score = linkedin_post_metric(dspy.Example(post_idea=test_case), result)\n",
    "        print(f\"\\nTest {i}: {test_case}\")\n",
    "        print(f\"Quality Score: {score:.3f}\")\n",
    "        print(f\"Hook: {result.hook}\")\n",
    "        print(f\"CTA: {result.call_to_action}\")\n",
    "\n",
    "analyze_optimizations(optimized_ghostwriter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec2df2",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Despite our training data only being 11 examples, we were still able to optimize our ghostwriter by about ~4%. In production, the more data we accumulate the more effective DSPy becomes. Thus we have shown that it can be a powerful tool in creating our data flywheel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
