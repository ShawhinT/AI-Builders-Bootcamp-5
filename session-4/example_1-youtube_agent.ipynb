{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# YouTube Agent with OpenAI Agents SDK\n",
    "## ABB #5 - Session 4\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "**Resources**\n",
    "- [YouTube video](https://youtu.be/-BUs1CPHKfU)\n",
    "- [Blog post](https://medium.com/@shawhin/how-to-improve-llms-with-tools-69cc68c804ed?sk=3ffd8308ce4905617b136a02cfa8dd83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from dotenv import load_dotenv\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a67ebc-ae9f-4857-bcd9-88b7b5341df5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# Suppress httpx INFO logs to reduce console output\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777be3cb-f501-45c1-a97d-064bbc73b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbe3d3-a590-45eb-be46-52791873b23f",
   "metadata": {},
   "source": [
    "### define instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50a5039-d46a-4cbb-90a0-22999a164df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You provide help with tasks related to YouTube videos.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d186d1d6-2950-4cec-8bda-d44321dbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def fetch_youtube_transcript(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract transcript with timestamps from a YouTube video URL and format it for LLM consumption\n",
    "    \n",
    "    Args:\n",
    "        url (str): YouTube video URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted transcript with timestamps, where each entry is on a new line\n",
    "             in the format: \"[MM:SS] Text\"\n",
    "    \"\"\"\n",
    "    # Extract video ID from URL\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    video_id_match = re.search(video_id_pattern, url)\n",
    "    \n",
    "    if not video_id_match:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "    video_id = video_id_match.group(1)\n",
    "    \n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        \n",
    "        # Format each entry with timestamp and text\n",
    "        formatted_entries = []\n",
    "        for entry in transcript:\n",
    "            # Convert seconds to MM:SS format\n",
    "            minutes = int(entry['start'] // 60)\n",
    "            seconds = int(entry['start'] % 60)\n",
    "            timestamp = f\"[{minutes:02d}:{seconds:02d}]\"\n",
    "            \n",
    "            formatted_entry = f\"{timestamp} {entry['text']}\"\n",
    "            formatted_entries.append(formatted_entry)\n",
    "        \n",
    "        # Join all entries with newlines\n",
    "        return \"\\n\".join(formatted_entries)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching transcript: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e213b4-c41b-4dc8-9213-c79ae13b2108",
   "metadata": {},
   "source": [
    "### create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a0ce90-c098-44e9-a823-182e71576bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"YouTube Transcript Agent\",\n",
    "    instructions=instructions,\n",
    "    tools=[fetch_youtube_transcript],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae7380-3e0d-4846-8fff-abb2d462bdb8",
   "metadata": {},
   "source": [
    "### main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86d9958-aeeb-49cd-9270-6b53b6929aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    input_items = []\n",
    "\n",
    "    print(\"=== YouTube Transcript Agent ===\")\n",
    "    print(\"Type 'exit' to end the conversation\")\n",
    "    print(\"Ask me anything about YouTube videos!\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        input_items.append({\"content\": user_input, \"role\": \"user\"})\n",
    "        \n",
    "        # Check for exit command\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        print(\"\\nAgent: \", end=\"\", flush=True)\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=input_items,\n",
    "        )\n",
    "\n",
    "        async for event in result.stream_events(): # not all events are available at outset, hence the async\n",
    "            # We'll ignore the raw responses event deltas\n",
    "            if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "                print(event.data.delta, end=\"\", flush=True)\n",
    "            elif event.type == \"run_item_stream_event\":\n",
    "                if event.item.type == \"tool_call_item\":\n",
    "                    print(\"\\n-- Fetching transcript...\")\n",
    "                elif event.item.type == \"tool_call_output_item\":\n",
    "                    input_items.append({\"content\": f\"Transcript:\\n{event.item.output}\", \"role\": \"system\"})\n",
    "                    print(\"-- Transcript fetched.\")\n",
    "                elif event.item.type == \"message_output_item\":\n",
    "                    input_items.append({\"content\": f\"{event.item.raw_item.content[0].text}\", \"role\": \"assistant\"})\n",
    "                else:\n",
    "                    pass  # Ignore other event types\n",
    "\n",
    "        print(\"\\n\")  # Add a newline after each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d78925-f897-43dd-8497-87760fa01983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YouTube Transcript Agent ===\n",
      "Type 'exit' to end the conversation\n",
      "Ask me anything about YouTube videos!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is this video about? https://youtu.be/ZaY5_ScmiFE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: \n",
      "-- Fetching transcript...\n",
      "-- Transcript fetched.\n",
      "The video is an introductory piece in a series on AI agents by Shaw. It explores the concept of AI agents, discussing their definitions and importance. Shaw examines varying definitions by organizations like OpenAI and Hugging Face and emphasizes key components of AI agents: the involvement of large language models (LLMs), tool usage, and autonomy.\n",
      "\n",
      "Key Points:\n",
      "1. **Definitions**: The video highlights differing definitions of AI agents, focusing on their configurations with instructions, tools, and planning capabilities.\n",
      "2. **Components of AI Agents**:\n",
      "   - **LLMs**: Central to AI agents, often augmented with additional software or frameworks.\n",
      "   - **Tool Use**: Extends the capabilities of LLMs beyond text generation, enabling interactions with reality.\n",
      "   - **Autonomy**: Involves planning, reasoning, and feedback for decision-making processes.\n",
      "\n",
      "3. **Levels of Agency**:\n",
      "   - **Level 1**: LLMs plus tools, useful for simple tasks.\n",
      "   - **Level 2**: LLM workflows, involving predefined steps and multiple LLMs for more complex tasks.\n",
      "   - **Level 3**: LLMs in a loop, using real-world feedback for iterative improvement.\n",
      "\n",
      "4. **Future Content**: Shaw plans to dive deeper into technical details and build specific agentic systems in future videos, seeking viewer suggestions on what to cover next.\n",
      "\n",
      "Overall, the video sets a foundational understanding of AI agents and their potential impact in the AI landscape.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Can you create chapter timestamps for this?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Sure, here are the chapter timestamps based on the video content:\n",
      "\n",
      "1. **Introduction to AI Agents** - 00:00\n",
      "2. **Defining AI Agents** - 00:36\n",
      "3. **Key Features of AI Agents** - 01:58\n",
      "4. **Tools and Usage** - 02:35\n",
      "5. **Autonomy and Agency** - 05:16\n",
      "6. **Levels of Agency** - 07:05\n",
      "7. **Level 1: LLMs Plus Tools** - 07:14\n",
      "8. **Level 2: LLM Workflows** - 11:31\n",
      "9. **Common Design Patterns** - 13:10\n",
      "10. **Level 3: LLM in a Loop** - 19:06\n",
      "11. **Future Video Content** - 22:52\n",
      "\n",
      "These timestamps should help navigate the key sections of the video.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Can you give me links to each chapter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Certainly! Here are the links to each chapter in the video:\n",
      "\n",
      "1. [**Introduction to AI Agents**](https://youtu.be/ZaY5_ScmiFE?t=0)\n",
      "2. [**Defining AI Agents**](https://youtu.be/ZaY5_ScmiFE?t=36)\n",
      "3. [**Key Features of AI Agents**](https://youtu.be/ZaY5_ScmiFE?t=118)\n",
      "4. [**Tools and Usage**](https://youtu.be/ZaY5_ScmiFE?t=155)\n",
      "5. [**Autonomy and Agency**](https://youtu.be/ZaY5_ScmiFE?t=316)\n",
      "6. [**Levels of Agency**](https://youtu.be/ZaY5_ScmiFE?t=425)\n",
      "7. [**Level 1: LLMs Plus Tools**](https://youtu.be/ZaY5_ScmiFE?t=434)\n",
      "8. [**Level 2: LLM Workflows**](https://youtu.be/ZaY5_ScmiFE?t=691)\n",
      "9. [**Common Design Patterns**](https://youtu.be/ZaY5_ScmiFE?t=790)\n",
      "10. [**Level 3: LLM in a Loop**](https://youtu.be/ZaY5_ScmiFE?t=1146)\n",
      "11. [**Future Video Content**](https://youtu.be/ZaY5_ScmiFE?t=1372)\n",
      "\n",
      "You can click these links to jump directly to each chapter in the video.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Goodbye!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "await main()\n",
    "# what is this video about? https://youtu.be/ZaY5_ScmiFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4f4b3-bcf6-4643-ad30-327c8ff416a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intro - 0:00\n",
    "What are AI agents? - 0:18\n",
    "Why Agents? - 3:37\n",
    "Level 1: LLM + Tool Use - 7:20\n",
    "Level 2: LLM Workflows - 11:29\n",
    "Level 3: LLM in a Loop - 19:05\n",
    "What's Next? - 22:52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to run in a .py script use\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
