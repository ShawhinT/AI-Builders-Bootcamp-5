{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# YouTube Agent with OpenAI Agents SDK\n",
    "## ABB #5 - Session 4\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "**Resources**\n",
    "- [YouTube video](https://youtu.be/-BUs1CPHKfU)\n",
    "- [Blog post](https://medium.com/@shawhin/how-to-improve-llms-with-tools-69cc68c804ed?sk=3ffd8308ce4905617b136a02cfa8dd83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from dotenv import load_dotenv\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a67ebc-ae9f-4857-bcd9-88b7b5341df5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# Suppress httpx INFO logs to reduce console output\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777be3cb-f501-45c1-a97d-064bbc73b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbe3d3-a590-45eb-be46-52791873b23f",
   "metadata": {},
   "source": [
    "### define instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50a5039-d46a-4cbb-90a0-22999a164df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You provide help with tasks related to YouTube videos.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d186d1d6-2950-4cec-8bda-d44321dbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def fetch_youtube_transcript(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract transcript with timestamps from a YouTube video URL and format it for LLM consumption\n",
    "    \n",
    "    Args:\n",
    "        url (str): YouTube video URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted transcript with timestamps, where each entry is on a new line\n",
    "             in the format: \"[MM:SS] Text\"\n",
    "    \"\"\"\n",
    "    # Extract video ID from URL\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    video_id_match = re.search(video_id_pattern, url)\n",
    "    \n",
    "    if not video_id_match:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "    video_id = video_id_match.group(1)\n",
    "    \n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        \n",
    "        # Format each entry with timestamp and text\n",
    "        formatted_entries = []\n",
    "        for entry in transcript:\n",
    "            # Convert seconds to MM:SS format\n",
    "            minutes = int(entry['start'] // 60)\n",
    "            seconds = int(entry['start'] % 60)\n",
    "            timestamp = f\"[{minutes:02d}:{seconds:02d}]\"\n",
    "            \n",
    "            formatted_entry = f\"{timestamp} {entry['text']}\"\n",
    "            formatted_entries.append(formatted_entry)\n",
    "        \n",
    "        # Join all entries with newlines\n",
    "        return \"\\n\".join(formatted_entries)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching transcript: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e213b4-c41b-4dc8-9213-c79ae13b2108",
   "metadata": {},
   "source": [
    "### create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a0ce90-c098-44e9-a823-182e71576bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"YouTube Transcript Agent\",\n",
    "    instructions=instructions,\n",
    "    tools=[fetch_youtube_transcript],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae7380-3e0d-4846-8fff-abb2d462bdb8",
   "metadata": {},
   "source": [
    "### main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86d9958-aeeb-49cd-9270-6b53b6929aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    input_items = []\n",
    "\n",
    "    print(\"=== YouTube Transcript Agent ===\")\n",
    "    print(\"Type 'exit' to end the conversation\")\n",
    "    print(\"Ask me anything about YouTube videos!\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        input_items.append({\"content\": user_input, \"role\": \"user\"})\n",
    "        \n",
    "        # Check for exit command\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        print(\"\\nAgent: \", end=\"\", flush=True)\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=input_items,\n",
    "        )\n",
    "\n",
    "        async for event in result.stream_events(): # not all events are available at outset, hence the async\n",
    "            # We'll ignore the raw responses event deltas\n",
    "            if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "                print(event.data.delta, end=\"\", flush=True)\n",
    "            elif event.type == \"run_item_stream_event\":\n",
    "                if event.item.type == \"tool_call_item\":\n",
    "                    print(\"\\n-- Fetching transcript...\")\n",
    "                elif event.item.type == \"tool_call_output_item\":\n",
    "                    input_items.append({\"content\": f\"Transcript:\\n{event.item.output}\", \"role\": \"system\"})\n",
    "                    print(\"-- Transcript fetched.\")\n",
    "                elif event.item.type == \"message_output_item\":\n",
    "                    input_items.append({\"content\": f\"{event.item.raw_item.content[0].text}\", \"role\": \"assistant\"})\n",
    "                else:\n",
    "                    pass  # Ignore other event types\n",
    "\n",
    "        print(\"\\n\")  # Add a newline after each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d78925-f897-43dd-8497-87760fa01983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YouTube Transcript Agent ===\n",
      "Type 'exit' to end the conversation\n",
      "Ask me anything about YouTube videos!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is this video about? https://youtu.be/ZaY5_ScmiFE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: \n",
      "-- Fetching transcript...\n",
      "-- Transcript fetched.\n",
      "The video is an introduction to a larger series about AI agents by Shaw. It starts by discussing what AI agents are and their significance. It reviews definitions from major organizations like OpenAI, Hugging Face, and Anthropic, comparing their emphasis on tools, planning, and autonomy.\n",
      "\n",
      "The video identifies three key features common to AI agents:\n",
      "\n",
      "1. **Large Language Models (LLMs)**: Central to AI agents, playing a major role in how they're defined.\n",
      "   \n",
      "2. **Tool Use**: Enhances the capabilities of LLMs, allowing them to interact with the real world, perform web searches, run Python scripts, etc.\n",
      "\n",
      "3. **Autonomy**: Different definitions focus on autonomy, the ability for agents to plan and dynamically control how they solve tasks.\n",
      "\n",
      "The video also discusses different levels of AI agentic systems:\n",
      "\n",
      "- **Level 1**: LLM plus tools.\n",
      "- **Level 2**: LLM workflows, like email responders.\n",
      "- **Level 3**: LLM in a loop, improving outputs through feedback and potential fine-tuning.\n",
      "\n",
      "The host emphasizes that AI agents represent a shift from vanilla chatbots by being more useful in real-world applications due to their ability to handle complexity and exercise autonomy. The video sets the stage for future videos where concrete examples and implementations will be explored.\n",
      "\n",
      "Shaw concludes by encouraging viewers to suggest topics and ideas for the series, acknowledging the vast and evolving landscape of AI agents.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Can you write chapter timestamps for it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Sure, here are the chapter timestamps based on the video content:\n",
      "\n",
      "1. **Introduction to AI Agents** - [00:00](#00:00)\n",
      "2. **Definitions of AI Agents** - [00:28](#00:28)\n",
      "3. **Key Features of AI Agents** - [01:54](#01:54)\n",
      "   - Large Language Models (LLMs)\n",
      "   - Tool Use\n",
      "   - Autonomy\n",
      "4. **Comparison with Chatbots** - [03:36](#03:36)\n",
      "5. **Levels of Agentic Systems** - [06:36](#06:36)\n",
      "   - Level 1: LLM + Tools\n",
      "   - Level 2: LLM Workflows\n",
      "   - Level 3: LLM in a Loop\n",
      "6. **Workflow Design Patterns** - [14:01](#14:01)\n",
      "   - Chaining\n",
      "   - Routing\n",
      "   - Parallelization\n",
      "   - Orchestrator-Workers\n",
      "   - Evaluator-Optimizer\n",
      "7. **Example of LLM in a Loop** - [18:50](#18:50)\n",
      "8. **Conclusion and Series Preview** - [22:52](#22:52) \n",
      "\n",
      "These timestamps provide a structured overview of the topics covered in the video.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Can you provide youtube links for each chapter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Certainly! Here are the chapter timestamps with YouTube links:\n",
      "\n",
      "1. **[Introduction to AI Agents](https://youtu.be/ZaY5_ScmiFE?t=0)**\n",
      "2. **[Definitions of AI Agents](https://youtu.be/ZaY5_ScmiFE?t=28)**\n",
      "3. **[Key Features of AI Agents](https://youtu.be/ZaY5_ScmiFE?t=114)**\n",
      "   - Large Language Models (LLMs)\n",
      "   - Tool Use\n",
      "   - Autonomy\n",
      "4. **[Comparison with Chatbots](https://youtu.be/ZaY5_ScmiFE?t=216)**\n",
      "5. **[Levels of Agentic Systems](https://youtu.be/ZaY5_ScmiFE?t=396)**\n",
      "   - Level 1: LLM + Tools\n",
      "   - Level 2: LLM Workflows\n",
      "   - Level 3: LLM in a Loop\n",
      "6. **[Workflow Design Patterns](https://youtu.be/ZaY5_ScmiFE?t=841)**\n",
      "   - Chaining\n",
      "   - Routing\n",
      "   - Parallelization\n",
      "   - Orchestrator-Workers\n",
      "   - Evaluator-Optimizer\n",
      "7. **[Example of LLM in a Loop](https://youtu.be/ZaY5_ScmiFE?t=1130)**\n",
      "8. **[Conclusion and Series Preview](https://youtu.be/ZaY5_ScmiFE?t=1372)**\n",
      "\n",
      "You can click on these links to jump directly to each section in the video.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (LLMs), tool usage, and autonomy. Definitions from various organizations like OpenAI and Hugging Face are discussed, highlighting different characteristics emphasized by each.\n",
      "\n",
      "The speaker explains key features of AI agents, namely LLM involvement, tool usage, and autonomy. These features allow agents to overcome limitations of traditional chatbots, interact with the real world, and solve complex tasks.\n",
      "\n",
      "Different levels of AI agents are presented:\n",
      "\n",
      "1. **Level 1: LLM Plus Tools** - Basic systems using tools to enhance LLM capabilities, such as web search or code execution.\n",
      "   \n",
      "2. **Level 2: LLM Workflows** - More advanced systems using workflows to manage tasks among multiple LLMs, improving performance through specialized roles.\n",
      "\n",
      "3. **Level 3: LLM in a Loop** - Systems that provide real-world feedback to refine outputs continuously, potentially using reinforcement learning for optimization.\n",
      "\n",
      "The video aims to lay the groundwork for future parts in the series, which will delve into technical details and build concrete examples of each type of system. The speaker invites viewer suggestions for future topics.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "await main()\n",
    "# what is this video about? https://youtu.be/ZaY5_ScmiFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to run in a .py script use\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
